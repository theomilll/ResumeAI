# Ferramenta de CategorizaÃ§Ã£o de Resumos de ReuniÃµes

Esta ferramenta permite treinar e usar modelos de Machine Learning para categorizar resumos de reuniÃµes em cinco categorias:
- AtualizaÃ§Ãµes de Projeto
- Achados de Pesquisa
- GestÃ£o de Equipe
- ReuniÃµes com Clientes
- Outras

## ğŸš€ Novidades - BERT Enhanced

**Novo modelo com 78% de acurÃ¡cia!** Principais melhorias implementadas:

- âœ… **+53% de melhoria** comparado ao modelo anterior
- âœ… **Aumento de dados automÃ¡tico** com text augmentation
- âœ… **Balanceamento inteligente** de classes desbalanceadas  
- âœ… **AnÃ¡lise de confianÃ§a** para cada prediÃ§Ã£o
- âœ… **Contexto expandido** (256 vs 128 tokens)
- âœ… **Early stopping** e regularizaÃ§Ã£o avanÃ§ada
- âœ… **IntegraÃ§Ã£o completa** na interface web

**Performance por categoria:**
- ğŸ¯ Achados de Pesquisa: **100%**
- ğŸ¯ ReuniÃµes com Clientes: **100%** 
- ğŸ¯ AtualizaÃ§Ãµes de Projeto: **90%**
- ğŸ¯ GestÃ£o de Equipe: **87.5%**

## PrÃ©-requisitos

- Python 3.8 ou superior
- Instale as dependÃªncias:

  ```bash
  pip install -r requirements.txt
  ```

## Estrutura do Projeto

```
â”œâ”€â”€ data/
â”‚   â””â”€â”€ resumos.csv         # Seu dataset de treinamento (colunas: text, category)
â”œâ”€â”€ models/                 # Modelos e encoders salvos
â”œâ”€â”€ src/                    # CÃ³digo-fonte
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ train_tfidf.py      # Pipeline TF-IDF + LogisticRegression
â”‚   â”œâ”€â”€ train_bert.py       # Pipeline BERT legacy
â”‚   â”œâ”€â”€ train_bert_enhanced.py  # Pipeline BERT Enhanced â­ (NOVO)
â”‚   â”œâ”€â”€ predict_tfidf.py    # CLI para modelo TF-IDF
â”‚   â””â”€â”€ predict_bert.py     # CLI para modelo BERT Enhanced â­ (NOVO)
â”œâ”€â”€ tests/                  # Testes automatizados
â””â”€â”€ requirements.txt
```

## Como Treinar

### 1) TF-IDF + LogisticRegression (maior percentual de sucesso nos treinos realizados)

```bash
python3 src/train_tfidf.py \
  --data_path data/resumos.csv \
  --label_column category \
  --output_dir models/tfidf
```

### 2) BERT Enhanced (RECOMENDADO - 78% de AcurÃ¡cia) â­

```bash
python3 src/train_bert_enhanced.py \
  --data_path data/resumos.csv \
  --use_augmentation \
  --epochs 10 \
  --batch_size 16
```

### 3) BERT Legacy

```bash
python3 src/train_bert.py \
  --data_path data/resumos.csv \
  --label_column category \
  --epochs 5 \
  --batch_size 8 \
  --output_dir models/bert_finetuned
```

### ExplicaÃ§Ã£o das EstratÃ©gias de Treino

#### TF-IDF + LogisticRegression (maior percentual de sucesso nos treinos realizados)
- VetorizaÃ§Ã£o: TF-IDF com uni- e bigramas (max_features=10000).
- Classificador: LogisticRegression com solver liblinear e class_weight='balanced'.
- Vantagens: rÃ¡pido, leve, dependÃªncias mÃ­nimas, serve como baseline para comparar.
- Caso de uso: validaÃ§Ãµes e testes iniciais, datasets menores ou desempenho em tempo real.

#### BERT Enhanced â­ (RECOMENDADO)
- **AcurÃ¡cia**: 78% no conjunto de validaÃ§Ã£o (significativa melhoria)
- **Modelo base**: Fine-tuning de `neuralmind/bert-base-portuguese-cased`
- **Melhorias implementadas**:
  - âœ… **Aumento de dados**: TÃ©cnicas de text augmentation (sinonÃ­mia, troca de palavras, exclusÃ£o aleatÃ³ria)
  - âœ… **Balanceamento de classes**: Pesos automÃ¡ticos para lidar com desbalanceamento
  - âœ… **HiperparÃ¢metros otimizados**: Learning rate com warmup, weight decay, gradient accumulation
  - âœ… **Contexto expandido**: SequÃªncias de atÃ© 256 tokens (vs. 128 anterior)
  - âœ… **Early stopping**: Evita overfitting com paciÃªncia de 3 Ã©pocas
  - âœ… **RegularizaÃ§Ã£o**: Dropout aumentado para melhor generalizaÃ§Ã£o
- **Performance por categoria**:
  - Achados de Pesquisa: 100% acurÃ¡cia
  - ReuniÃµes com Clientes: 100% acurÃ¡cia  
  - AtualizaÃ§Ãµes de Projeto: 90% acurÃ¡cia
  - GestÃ£o de Equipe: 87.5% acurÃ¡cia
  - Outras: Categoria mais desafiadora (necessita mais dados)
- **Vantagens**: Melhor precisÃ£o, anÃ¡lise de confianÃ§a, tratamento robusto de classes desbalanceadas
- **Caso de uso**: AplicaÃ§Ãµes de produÃ§Ã£o que exigem alta acurÃ¡cia

#### BERT Legacy
- Pipeline: fine-tuning bÃ¡sico de `neuralmind/bert-base-portuguese-cased`
- ConfiguraÃ§Ãµes: epochs=5, batch_size=8, max_len=128
- Vantagens: Mais rÃ¡pido para treinar, menor uso de memÃ³ria
- Caso de uso: Testes rÃ¡pidos e desenvolvimento inicial

## Como Prever

### BERT Enhanced (RECOMENDADO) â­

```bash
# PrediÃ§Ã£o simples
python3 src/predict_bert.py "Seu texto de reuniÃ£o aqui"

# Com anÃ¡lise de confianÃ§a
python3 src/predict_bert.py "Seu texto de reuniÃ£o aqui" --show_confidence
```

### TF-IDF + LogisticRegression

```bash
python3 src/predict_tfidf.py "Seu texto de reuniÃ£o aqui"
```

#### Dica para facilitar a execuÃ§Ã£o

Adicione um alias no seu shell (~/.bashrc ou ~/.zshrc):

```bash
alias predict="python3 src/predict_tfidf.py"
```

A partir de entÃ£o, basta executar:

```bash
predict "Resumo da reuniÃ£o"
```
```
